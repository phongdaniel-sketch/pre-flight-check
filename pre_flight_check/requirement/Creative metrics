Ph√¢n t√≠ch Video TikTok b·∫±ng AI

T√†i li·ªáu n√†y tr√¨nh b√†y ki·∫øn tr√∫c v√† m√£ ngu·ªìn chi ti·∫øt ƒë·ªÉ x√¢y d·ª±ng m·ªôt h·ªá th·ªëng t·ª± ƒë·ªông ph√¢n t√≠ch v√† ch·∫•m ƒëi·ªÉm video theo c√°c ti√™u ch√≠ "h·∫•p d·∫´n" c·ªßa n·ªÅn t·∫£ng TikTok.

## üèõÔ∏è 1. Ki·∫øn tr√∫c T·ªïng quan

H·ªá th·ªëng ƒë∆∞·ª£c thi·∫øt k·∫ø theo d·∫°ng pipeline, x·ª≠ l√Ω video qua nhi·ªÅu module chuy√™n bi·ªát. ƒê·∫ßu v√†o l√† file video v√† ƒë·∫ßu ra l√† m·ªôt file JSON ch·ª©a k·∫øt qu·∫£ ph√¢n t√≠ch.

```
                  +-------------------------+
Input Video ----> | 1. Pre-Analysis Module  | --(Duration, FPS)-->
                  |   - Ki·ªÉm tra th·ªùi l∆∞·ª£ng |
                  +-------------------------+
                          |
                          v
                  +-------------------------+
                  | 2. Visual Analysis Module | --(Safe Zone, Scene Cuts, Text, Objects)-->
                  |   - Ph√¢n t√≠ch t·ª´ng Frame |
                  +-------------------------+
                          |
                          v
                  +-------------------------+
                  | 3. Audio Analysis Module  | --(Tempo, Voiceover)-->
                  |   - Ph√¢n t√≠ch √¢m thanh   |
                  +-------------------------+
                          |
                          v
                  +-------------------------+
                  |  4. Scoring Engine      | --(Hook Score, Pacing Score)-->
                  |   - T√≠nh to√°n ƒëi·ªÉm s·ªë    |
                  +-------------------------+
                          |
                          v
                  +-------------------------+
                  |     Final JSON Output   |
                  +-------------------------+
```

## üõ†Ô∏è 2. C√†i ƒë·∫∑t M√¥i tr∆∞·ªùng

M·ªü Terminal (ho·∫∑c Command Prompt) v√† c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán Python c·∫ßn thi·∫øt. M·ªói th∆∞ vi·ªán ph·ª•c v·ª• m·ªôt m·ª•c ƒë√≠ch c·ª• th·ªÉ trong pipeline.

```bash
# Th∆∞ vi·ªán x·ª≠ l√Ω video v√† h√¨nh ·∫£nh c·ªët l√µi
pip install opencv-python

# Th∆∞ vi·ªán nh·∫≠n di·ªán ch·ªØ trong ·∫£nh (OCR)
pip install easyocr

# Th∆∞ vi·ªán chuy√™n ƒë·ªÉ ph√°t hi·ªán chuy·ªÉn c·∫£nh
pip install scenedetect[opencv]

# Th∆∞ vi·ªán ph√¢n t√≠ch √¢m thanh
pip install librosa moviepy

# (T√πy ch·ªçn nh∆∞ng khuy·∫øn ngh·ªã) Th∆∞ vi·ªán AI m·∫°nh m·∫Ω c·ªßa PyTorch
pip install torch torchvision torchaudio
```

## üíª 3. Code Ho√†n ch·ªânh

D∆∞·ªõi ƒë√¢y l√† m√£ ngu·ªìn Python ho√†n ch·ªânh cho l·ªõp `TikTokVideoAnalyzer`, bao g·ªìm t·∫•t c·∫£ c√°c logic ph√¢n t√≠ch ƒë√£ ƒë·ªÅ c·∫≠p.

```python
import cv2
import numpy as np
import easyocr
from scenedetect import open_video, SceneManager
from scenedetect.detectors import ContentDetector
from moviepy.editor import VideoFileClip
import librosa
import os
import json

class TikTokVideoAnalyzer:
    """
    M·ªôt l·ªõp ho√†n ch·ªânh ƒë·ªÉ ph√¢n t√≠ch v√† ch·∫•m ƒëi·ªÉm video TikTok d·ª±a tr√™n c√°c ti√™u ch√≠
    v·ªÅ th·ªùi l∆∞·ª£ng, nh·ªãp ƒë·ªô, v√† c√°c y·∫øu t·ªë thu h√∫t.
    """
    def __init__(self, video_path):
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"Video file not found at: {video_path}")
        self.video_path = video_path
        self.cap = cv2.VideoCapture(video_path)
        self.fps = self.cap.get(cv2.CAP_PROP_FPS)
        self.frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self.duration = self.frame_count / self.fps
        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print("Initializing EasyOCR...")
        # H·ªó tr·ª£ ti·∫øng Anh v√† ti·∫øng Vi·ªát
        self.ocr_reader = easyocr.Reader(['en', 'vi'], gpu=True) # Set gpu=False n·∫øu kh√¥ng c√≥ GPU

    def _check_safe_zone(self, important_elements):
        """
        Ki·ªÉm tra xem c√°c y·∫øu t·ªë quan tr·ªçng (vƒÉn b·∫£n, khu√¥n m·∫∑t) c√≥ n·∫±m trong v√πng an to√†n kh√¥ng.
        Input: a list of bounding boxes [(x1, y1, x2, y2), ...]
        """
        # T·ªça ƒë·ªô c√°c v√πng UI c·ªßa TikTok (∆∞·ªõc t√≠nh theo t·ª∑ l·ªá)
        ui_zones = [
            # V√πng caption v√† t√™n user ·ªü d∆∞·ªõi (70% chi·ªÅu r·ªông, 20% chi·ªÅu cao d∆∞·ªõi)
            (0, self.height * 0.8, self.width * 0.7, self.height), 
            # V√πng c√°c n√∫t like, comment, share b√™n ph·∫£i (15% chi·ªÅu r·ªông b√™n ph·∫£i, 40% chi·ªÅu cao ·ªü gi·ªØa)
            (self.width * 0.85, self.height * 0.4, self.width, self.height * 0.8)
        ]
        
        is_safe = True
        for element_box in important_elements:
            ex1, ey1, ex2, ey2 = element_box
            for ux1, uy1, ux2, uy2 in ui_zones:
                # Ki·ªÉm tra s·ª± ch·ªìng l·∫•n (intersection)
                if not (ex2 < ux1 or ex1 > ux2 or ey2 < uy1 or ey1 > uy2):
                    is_safe = False
                    break
            if not is_safe:
                break
        return is_safe

    def analyze_duration(self):
        """Ki·ªÉm tra th·ªùi l∆∞·ª£ng video c√≥ n·∫±m trong kho·∫£ng 15s-45s kh√¥ng."""
        is_valid = 15 <= self.duration <= 45
        return {
            "duration_seconds": round(self.duration, 2),
            "is_valid_duration": is_valid
        }

    def analyze_scenes(self):
        """Ph√°t hi·ªán c√°c c·∫£nh, t√≠nh to√°n nh·ªãp ƒë·ªô v√† ch·∫•m ƒëi·ªÉm pacing_score."""
        video = open_video(self.video_path)
        scene_manager = SceneManager()
        scene_manager.add_detector(ContentDetector(threshold=27.0))
        scene_manager.detect_scenes(video, show_progress=False)
        scene_list = scene_manager.get_scene_list()
        
        # L·∫•y timestamp c·ªßa ƒëi·ªÉm k·∫øt th√∫c m·ªói c·∫£nh (c≈©ng l√† ƒëi·ªÉm b·∫Øt ƒë·∫ßu c·∫£nh m·ªõi)
        scene_cuts = [scene.get_seconds() for scene in scene_list]
        num_scenes = len(scene_list)
        
        pacing_rate = self.duration / num_scenes if num_scenes > 0 else self.duration

        # Ch·∫•m ƒëi·ªÉm Pacing d·ª±a tr√™n benchmark
        if 1.5 <= pacing_rate <= 2.5:
            pacing_score = 100
        elif pacing_rate > 4.0:
            pacing_score = 40
        elif pacing_rate > 2.5:
            # ƒêi·ªÉm gi·∫£m d·∫ßn tuy·∫øn t√≠nh t·ª´ 100 xu·ªëng 40
            pacing_score = 40 + (4.0 - pacing_rate) / (4.0 - 2.5) * 60
        else: # pacing_rate < 1.5
            pacing_score = 80 # Nh·ªãp qu√° nhanh v·∫´n t·ªët nh∆∞ng c√≥ th·ªÉ h∆°i r·ªëi
            
        return {
            "scene_cuts_timestamp": scene_cuts,
            "number_of_scenes": num_scenes,
            "pacing_rate_sec_per_scene": round(pacing_rate, 2),
            "pacing_score": int(pacing_score)
        }

    def analyze_hook(self, scene_cuts):
        """Ph√¢n t√≠ch 3 gi√¢y ƒë·∫ßu ƒë·ªÉ ch·∫•m ƒëi·ªÉm Hook."""
        hook_score = 0
        hook_factors = { "has_text": False, "has_fast_cut": False, "has_human": False }
        
        # 1. Ki·ªÉm tra chuy·ªÉn c·∫£nh nhanh trong 3s ƒë·∫ßu
        if any(cut <= 3.0 for cut in scene_cuts):
            hook_score += 40
            hook_factors["has_fast_cut"] = True

        # 2. ƒê·ªçc c√°c frame trong 3s ƒë·∫ßu ƒë·ªÉ ki·ªÉm tra text v√† ng∆∞·ªùi
        frames_to_check = int(self.fps * 3)
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0) # Tua v·ªÅ ƒë·∫ßu video
        
        text_found = False
        
        for i in range(frames_to_check):
            ret, frame = self.cap.read()
            if not ret: break
            
            # Ch·ªâ ki·ªÉm tra m·ªói 10 frame ƒë·ªÉ t·ªëi ∆∞u
            if i % 10 == 0:
                if not text_found:
                    results = self.ocr_reader.readtext(frame, detail=0, paragraph=True)
                    if results:
                        text_found = True
        
        hook_factors["has_text"] = text_found

        # T·∫°m th·ªùi gi·∫£ ƒë·ªãnh l√† t√¨m th·∫•y ng∆∞·ªùi. C·∫ßn t√≠ch h·ª£p model object detection (YOLO, SSD) ƒë·ªÉ l√†m th·∫≠t.
        human_found = True 
        hook_factors["has_human"] = human_found
            
        if text_found: hook_score += 35
        if human_found: hook_score += 25
            
        return { "hook_score": min(hook_score, 100), "hook_factors": hook_factors }
    
    def analyze_audio(self):
        """Ph√¢n t√≠ch file √¢m thanh ƒë·ªÉ l·∫•y nh·ªãp ƒë·ªô (tempo) v√† ki·ªÉm tra gi·ªçng n√≥i."""
        try:
            audio_path = "temp_audio.wav"
            # Tr√≠ch xu·∫•t audio t·ª´ video
            video_clip = VideoFileClip(self.video_path)
            video_clip.audio.write_audiofile(audio_path, codec='pcm_s16le', logger=None)
            
            # T·∫£i file audio ƒë√£ tr√≠ch xu·∫•t
            y, sr = librosa.load(audio_path)
            # ∆Ø·ªõc t√≠nh tempo
            tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
            
            # Placeholder cho vi·ªác ph√°t hi·ªán gi·ªçng n√≥i
            has_voiceover = False 
            
            os.remove(audio_path) # D·ªçn d·∫πp file t·∫°m
            return {
                "music_tempo_bpm": int(tempo),
                "audio_vibe": "fast" if tempo > 120 else "slow",
                "has_voiceover": has_voiceover
            }
        except Exception as e:
            print(f"Audio analysis failed or video has no audio: {e}")
            return { "music_tempo_bpm": 0, "audio_vibe": "unknown", "has_voiceover": False }

    def run_full_analysis(self):
        """Ch·∫°y to√†n b·ªô pipeline v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ cu·ªëi c√πng d∆∞·ªõi d·∫°ng dictionary."""
        print("1. Analyzing duration...")
        duration_result = self.analyze_duration()
        
        print("2. Analyzing scenes and pacing...")
        scene_result = self.analyze_scenes()
        
        print("3. Analyzing 3-second hook...")
        hook_result = self.analyze_hook(scene_result["scene_cuts_timestamp"])
        
        print("4. Analyzing audio...")
        audio_result = self.analyze_audio()
        
        # Placeholder cho c√°c ph√¢n t√≠ch h√¨nh ·∫£nh n√¢ng cao h∆°n
        safe_zone_passed = True # C·∫ßn logic _check_safe_zone v·ªõi bounding box th·∫≠t
        visual_elements = ["person", "text_overlay"] # C·∫ßn logic object detection th·∫≠t
        
        final_result = {
            "video_path": self.video_path,
            "duration_analysis": duration_result,
            "safe_zone_passed": safe_zone_passed,
            "hook_analysis": hook_result,
            "pacing_analysis": scene_result,
            "audio_analysis": audio_result,
            "visual_elements_detected": visual_elements,
        }
        
        self.cap.release()
        return final_result

# --- H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG ---
if __name__ == "__main__":
    try:
        # THAY ƒê·ªîI ƒê∆Ø·ªúNG D·∫™N N√ÄY
        video_file = "path/to/your/tiktok_video.mp4" 
        
        analyzer = TikTokVideoAnalyzer(video_file)
        result = analyzer.run_full_analysis()
        
        # In k·∫øt qu·∫£ ra m√†n h√¨nh
        print("\n--- ‚úÖ ANALYSIS COMPLETE ---")
        print(json.dumps(result, indent=4, ensure_ascii=False))

        # L∆∞u k·∫øt qu·∫£ ra file JSON
        output_filename = os.path.splitext(os.path.basename(video_file)) + "_analysis.json"
        with open(output_filename, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=4, ensure_ascii=False)
        print(f"\nüìÑ Result saved to: {output_filename}")

    except FileNotFoundError as e:
        print(f"‚ùå ERROR: {e}")
    except Exception as e:
        print(f"‚ùå An unexpected error occurred: {e}")

```

## üöÄ 4. C√°ch s·ª≠ d·ª•ng

1.  **L∆∞u file:** Sao ch√©p to√†n b·ªô code Python ·ªü tr√™n v√† l∆∞u v√†o m·ªôt file c√≥ t√™n `analyzer.py`.
2.  **Ch·ªânh s·ª≠a ƒë∆∞·ªùng d·∫´n:** M·ªü file `analyzer.py` v√† thay ƒë·ªïi gi√° tr·ªã c·ªßa bi·∫øn `video_file` ·ªü g·∫ßn cu·ªëi file th√†nh ƒë∆∞·ªùng d·∫´n ch√≠nh x√°c ƒë·∫øn video b·∫°n mu·ªën ph√¢n t√≠ch.
    ```python
    # THAY ƒê·ªîI ƒê∆Ø·ªúNG D·∫™N N√ÄY
    video_file = "path/to/your/tiktok_video.mp4"
    ```
3.  **Ch·∫°y ph√¢n t√≠ch:** M·ªü Terminal/Command Prompt, di chuy·ªÉn ƒë·∫øn th∆∞ m·ª•c ch·ª©a file `analyzer.py` v√† ch·∫°y l·ªánh:
    ```bash
    python analyzer.py
    ```
4.  **Xem k·∫øt qu·∫£:**
    *   To√†n b·ªô qu√° tr√¨nh ph√¢n t√≠ch s·∫Ω ƒë∆∞·ª£c t·ªïng h·ª£p v√† ƒë∆∞a ra m√†n h√¨nh k·∫øt qu·∫£.
    *   Khi ho√†n t·∫•t, k·∫øt qu·∫£ chi ti·∫øt s·∫Ω ƒë∆∞·ª£c l∆∞u v√†o m·ªôt file JSON m·ªõi (v√≠ d·ª•: `tiktok_video_analysis.json`) trong c√πng th∆∞ m·ª•c.

## üîÆ 5. H∆∞·ªõng t√≠nh to√°n DNA score
Khi input video, h·ªá th·ªëng s·∫Ω th·ª±c hi·ªán:
    Qu√©t Safe Zone (ƒë·∫£m b·∫£o kh√¥ng b·ªã che b·ªüi UI TikTok) --> tr·∫£ k·∫øt qu·∫£?
    Ki·ªÉm tra th·ªùi l∆∞·ª£ng (c√≥ n·∫±m trong 15s-45s kh√¥ng) --> tr·∫£ k·∫øt qu·∫£?
    Ch·∫•m ƒëi·ªÉm "DNA h·∫•p d·∫´n" (Hook, Nh·ªãp c·∫Øt c·∫£nh): (chi ti·∫øt)
Sau ƒë√≥ t√≠nh to√°n:
    Hook (3s ƒë·∫ßu): AI ki·ªÉm tra xem trong 3 gi√¢y ƒë·∫ßu c√≥: (1) Text g√¢y s·ªëc/t√≤ m√≤, (2) S·ª± thay ƒë·ªïi khung h√¨nh nhanh, (3) Xu·∫•t hi·ªán s·∫£n ph·∫©m/con ng∆∞·ªùi r√µ r√†ng kh√¥ng?
    Pacing (Nh·ªãp ƒë·ªô): AI ƒë·∫øm s·ªë l·∫ßn chuy·ªÉn c·∫£nh (cut) trong video.
    C√¥ng th·ª©c: Pacing Rate = T·ªïng th·ªùi l∆∞·ª£ng / S·ªë l∆∞·ª£ng c·∫£nh.
    Benchmark: TikTok c·ª±c k·ª≥ ∆∞u ti√™n nh·ªãp t·ª´ 1.5s - 2.5s/c·∫£nh. N·∫øu nh·ªãp > 4s/c·∫£nh -> Video b·ªã coi l√† ch·∫≠m/ch√°n.
Ch·∫•m ƒëi·ªÉm nh∆∞ sau:
    hook_score (0-100): D·ª±a tr√™n 3s ƒë·∫ßu c√≥ ƒë·ªß y·∫øu t·ªë gi·ªØ ch√¢n ng∆∞·ªùi d√πng kh√¥ng.
    scene_cuts: Danh s√°ch c√°c m·ªëc th·ªùi gian (timestamp) m√† video chuy·ªÉn c·∫£nh.
    visual_elements: Danh s√°ch c√°c y·∫øu t·ªë xu·∫•t hi·ªán (ng∆∞·ªùi m·∫´u, text overlay, unboxing, kho h√†ng).
    audio_vibe: Nh·∫°c nhanh hay ch·∫≠m, c√≥ gi·ªçng ƒë·ªçc (voiceover) kh√¥ng. Sau ƒë√≥, t√≠nh pacing_score: N·∫øu trung b√¨nh m·ªói c·∫£nh d√†i 1.5s-2.5s th√¨ cho 100 ƒëi·ªÉm, n·∫øu > 4s th√¨ cho 40 ƒëi·ªÉm."
C√¥ng th·ª©c: DNA Score = (Hook * 0.6) + (Pacing * 0.4).
